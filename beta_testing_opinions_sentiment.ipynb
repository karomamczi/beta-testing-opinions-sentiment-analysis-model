{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beta Testing Opinions | Sentiment Analysis Model\n",
    "\n",
    "_Author: Karolina Mamczarz_\n",
    "\n",
    "_Based on: [Deep Learning Nanodegree Program | Udacity](https://www.udacity.com/course/deep-learning-nanodegree--nd101)_\n",
    "\n",
    "_Code sources:_ \n",
    "* _[Udacity SageMaker deployment project](https://github.com/udacity/sagemaker-deployment/tree/master/Project)_\n",
    "* _[Udacity Recurrent Neural Networks | Sentiment Analysis RNN](https://github.com/udacity/deep-learning-v2-pytorch/tree/master/sentiment-rnn)_\n",
    "* _[Amazon Review Data (2018) | Code](https://nijianmo.github.io/amazon/index.html)_\n",
    "\n",
    "\n",
    "## Description\n",
    "\n",
    "PyTorch is used as a training tool. It is an open source machine learning framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "Reaserch will use [Amazon Review Data (2018)](https://nijianmo.github.io/amazon/index.html) datasets (downloaded on March 4th, 2020):\n",
    "* [Video Games subset](http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Video_Games_5.json.gz)\n",
    "* [Software subset](http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Software_5.json.gz)\n",
    "\n",
    "See citiation below:\n",
    "\n",
    "> Jianmo Ni, Jiacheng Li, Julian McAuley, **Justifying recommendations using distantly-labeled reviews and fined-grained aspects**, _Empirical Methods in Natural Language Processing (EMNLP)_, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read sentiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "\n",
    "def parse_dataset(path):\n",
    "  g = gzip.open(path, 'r')\n",
    "  for l in g:\n",
    "    yield json.loads(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_data(path):\n",
    "    data = {'pos': [], 'neg': []}\n",
    "    labels = {'pos': [], 'neg': []}\n",
    "\n",
    "    for review in parse_dataset(path):\n",
    "        if 'reviewText' in review:\n",
    "            if review['overall'] >= 4.0:\n",
    "                data['pos'].append(review['reviewText'])\n",
    "                labels['pos'].append(1)\n",
    "            elif review['overall'] <= 2.0:\n",
    "                data['neg'].append(review['reviewText'])\n",
    "                labels['neg'].append(0)\n",
    "    \n",
    "    for sentiment in ['pos', 'neg']:\n",
    "        assert len(data[sentiment]) == len(labels[sentiment]), \\\n",
    "                    \"{} data size does not match labels size\".format(sentiment)\n",
    "    \n",
    "    return data, labels   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews Video Games: 393267 pos / 55012 neg\n",
      "Reviews Software: 8987 pos / 2219 neg\n"
     ]
    }
   ],
   "source": [
    "video_games_data, video_games_labels = get_sentiment_data('./data/Video_Games_5.json.gz')\n",
    "software_data, software_labels = get_sentiment_data('./data/Software_5.json.gz')\n",
    "\n",
    "print('Reviews Video Games: {} pos / {} neg'.format(len(video_games_data['pos']), len(video_games_data['neg'])))\n",
    "print('Reviews Software: {} pos / {} neg'.format(len(software_data['pos']), len(software_data['neg'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_sentiment_data(data1, data2, labels1, labels2):\n",
    "    data = {'pos': [], 'neg': []}\n",
    "    labels = {'pos': [], 'neg': []}\n",
    "    \n",
    "    for sentiment in ['pos', 'neg']:\n",
    "        data[sentiment] = data1[sentiment] + data2[sentiment]\n",
    "        labels[sentiment] = labels1[sentiment] + labels2[sentiment]\n",
    "    \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: 402254 pos / 57231 neg\n"
     ]
    }
   ],
   "source": [
    "pre_data, pre_labels = join_sentiment_data(video_games_data, software_data, video_games_labels, software_labels)\n",
    "\n",
    "print('Data: {} pos / {} neg'.format(len(pre_data['pos']), len(pre_data['neg'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_sentiment_data(data, limit=25000):\n",
    "    new_data = {'pos': [], 'neg': []}\n",
    "\n",
    "    for sentiment in ['pos', 'neg']:\n",
    "        new_data[sentiment] = data[sentiment][0:limit]\n",
    "        \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: 25000 pos / 25000 neg\n",
      "Labels: 25000 pos / 25000 neg\n"
     ]
    }
   ],
   "source": [
    "data = crop_sentiment_data(pre_data)\n",
    "labels = crop_sentiment_data(pre_labels)\n",
    "\n",
    "print('Data: {} pos / {} neg'.format(len(data['pos']), len(data['neg'])))\n",
    "print('Labels: {} pos / {} neg'.format(len(labels['pos']), len(labels['neg'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_sentiment_data(data, labels):\n",
    "    all_data = data['pos'] + data['neg']\n",
    "    all_labels = labels['pos'] + labels['neg']\n",
    "    \n",
    "    return all_data, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: 50000\n",
      "Labels: 50000\n"
     ]
    }
   ],
   "source": [
    "all_data, all_labels = combine_sentiment_data(data, labels)\n",
    "print('Data: {}'.format(len(all_data)))\n",
    "print('Labels: {}'.format(len(all_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up sentiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def review_to_words(review):\n",
    "    nltk.download(\"stopwords\", quiet=True)\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    text = BeautifulSoup(review, \"html.parser\").get_text()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    words = text.split()\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")]\n",
    "    words = [PorterStemmer().stem(w) for w in words]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rememb', 'first', 'time', 'laid', 'eye', 'game', 'hear', 'awesom', 'nintendo', '64', 'go', 'schoolmat', 'eagerli', 'anticip', 'usa', 'releas', 'system', 'rememb', 'hear', 'demand', 'ensu', 'shortag', 'upcom', 'christma', 'even', 'saw', 'one', 'day', 'christma', 'shop', 'dad', 'happen', 'come', 'across', 'demo', 'set', 'mall', 'final', 'got', 'see', 'massiv', 'hype', 'game', 'bright', 'color', 'mario', 'fulli', '3d', 'larg', 'crowd', 'gather', 'around', 'catch', 'glimps', 'latest', 'video', 'game', 'technolog', 'linger', 'moment', 'yet', 'first', 'impress', 'still', 'fresh', 'memori', 'mario', '64', 'look', 'like', 'noth', 'ever', 'seen', 'also', 'look', 'leap', 'bound', 'better', 'anyth', 'ever', 'seen', 'playstat', 'sega', 'saturn', 'system', 'impress', 'sever', 'month', 'later', 'final', 'save', 'enough', 'money', 'purchas', 'system', 'bundl', 'mario', '64', 'love', 'game', 'dearli', 'back', 'day', 'still', 'love', 'game', 'still', 'look', 'feel', 'play', 'unlik', 'game', 'came', 'era', 'zelda', 'ocarina', 'time', 'similar', 'graphic', 'wise', 'game', 'great', 'right', 'game', 'deserv', 'recogn', 'separ', 'mario', '64', 'perfect', 'launch', 'game', 'nintendo', '64', 'home', 'consol', 'system', 'look', 'control', 'n64', 'one', 'might', 'understand', 'skeptic', 'due', 'layout', 'howev', 'mario', '64', 'actual', 'easi', 'control', 'good', 'introduct', 'get', 'gamer', 'accustom', 'new', 'feel', 'control', 'new', 'button', 'layout', 'say', 'control', 'game', 'simpl', 'must', 'also', 'mention', 'mario', 'capabl', 'mani', 'action', 'mario', 'walk', 'run', 'crawl', 'jump', 'tripl', 'jump', 'backflip', 'side', 'somersault', 'wall', 'kick', 'swim', 'climb', 'punch', 'kick', 'slide', 'fli', 'shoot', 'cannon', 'butt', 'splash', 'hang', 'hand', 'hand', 'crouch', 'surf', 'koopa', 'shell', 'even', 'look', 'around', 'scope', 'action', 'seem', 'like', 'lot', 'like', 'difficult', 'master', 'realiti', 'ye', 'alot', 'difficult', 'master', 'skill', 'wall', 'kick', 'fli', 'take', 'practic', 'master', 'major', 'mario', 'action', 'easi', 'master', 'result', 'fluid', 'gameplay', 'sensat', 'actual', 'mario', 'camera', 'angl', 'manag', 'consid', 'control', 'might', 'find', 'slightli', 'frustrat', 'certain', 'enclos', 'area', 'boo', 'haunt', 'hous', 'part', 'camera', 'angl', 'function', 'gameplay', 'extrem', 'fun', 'gradual', 'learn', 'curv', 'need', '60', 'star', 'complet', 'game', 'player', 'look', 'one', 'challeng', 'elect', 'tri', 'collect', '120', 'star', 'requir', 'true', 'masteri', 'game', 'music', 'outstand', 'koji', 'kondo', 'also', 'famou', 'ocarina', 'time', 'music', 'music', 'mario', '64', 'succeed', 'compos', 'memor', 'enjoy', 'tune', 'person', 'favorit', 'alway', 'jolli', 'rodger', 'bay', 'dire', 'dire', 'dock', 'music', 'level', 'design', 'uniqu', 'truli', 'larg', 'level', 'offer', 'ton', 'explor', 'mario', 'find', 'sunken', 'ship', 'cave', 'toxic', 'ga', 'insid', 'volcano', 'pyramid', 'desert', 'fortress', 'sky', 'slide', 'slipperi', 'snowi', 'slope', 'even', 'insid', 'giant', 'strang', 'clock', 'game', 'fill', 'fun', 'challeng', 'hour', 'terrif', 'gameplay', 'believ', 'ever', 'met', 'anyon', 'find', 'game', 'fun', 'play', 'luigi', 'game', 'major', 'hoax', 'cite', 'ridicul', 'method', 'would', 'unlock', 'luigi', 'prove', 'untru', 'kind', 'strang', 'luigi', 'game', 'big', 'deal', 'mario', '64', 'well', 'love', 'rememb', 'kind', 'strang', 'nintendo', '64', 'launch', 'game', 'almost', 'incompar', 'entir', 'librari', 'game', 'follow', 'super', 'mario', 'world', 'super', 'nintendo', 'gem', 'great', 'game', 'sne', 'librari', 'howev', 'nintendo', '64', 'super', 'mario', '64', 'along', 'zelda', 'ocarina', 'time', 'stand', 'head', 'shoulder', 'pretti', 'much', 'everi', 'game', 'nintendo', '64', 'librari', 'disappoint', 'consid', 'see', 'nintendo', '64', 'capabl', 'support', 'top', 'notch', 'game', 'nintendo', '64', 'librari', 'manag', 'produc', 'game', 'live', 'origin', 'launch', 'game', 'end', 'mario', '64', 'alway', 'rememb', 'revolutionari', 'classic', 'liter', 'defin', 'nintendo', '64', 'bit', 'era']\n"
     ]
    }
   ],
   "source": [
    "print(review_to_words(all_data[1266]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, os\n",
    "\n",
    "cache_dir = os.path.join(\"./cache\", \"sentiment_analysis\")\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "def reviews_to_words(data, cache_dir=cache_dir, cache_file=\"preprocessed_data.pkl\"):\n",
    "    cache_data = None\n",
    "    if cache_file is not None:\n",
    "        try:\n",
    "            with open(os.path.join(cache_dir, cache_file), \"rb\") as f:\n",
    "                cache_data = pickle.load(f)\n",
    "            print(\"Read preprocessed data from cache file:\", cache_file)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    if cache_data is None:\n",
    "        words = [review_to_words(review) for review in data]\n",
    "        \n",
    "        if cache_file is not None:\n",
    "            cache_data = dict(words=words)\n",
    "            with open(os.path.join(cache_dir, cache_file), \"wb\") as f:\n",
    "                pickle.dump(cache_data, f)\n",
    "            print(\"Wrote preprocessed data to cache file:\", cache_file)\n",
    "    else:\n",
    "        words = cache_data['words']\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read preprocessed data from cache file: preprocessed_data.pkl\n"
     ]
    }
   ],
   "source": [
    "reviews_words = reviews_to_words(all_data)\n",
    "all_words = [item for sublist in reviews_words for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def tokenize_words(all_words, reviews_words):\n",
    "    counts = Counter(all_words)\n",
    "    vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "    vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
    "    reviews_ints = []\n",
    "    for review_words in reviews_words:\n",
    "        reviews_ints.append([vocab_to_int[word] for word in review_words])\n",
    "        \n",
    "    return vocab_to_int, reviews_ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words: 50770\n",
      "Tokenized review: \n",
      " [[1, 137, 83, 4, 1219, 11]]\n"
     ]
    }
   ],
   "source": [
    "vocab_to_int, pre_reviews_ints = tokenize_words(all_words, reviews_words)\n",
    "\n",
    "print('Unique words: {}'.format(len((vocab_to_int))))\n",
    "print('Tokenized review: \\n {}'.format(pre_reviews_ints[:1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove zero-length reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-length reviews: 55\n",
      "Maximum review length: 2996\n"
     ]
    }
   ],
   "source": [
    "review_lens = Counter([len(x) for x in pre_reviews_ints])\n",
    "\n",
    "print('Zero-length reviews: {}'.format(review_lens[0]))\n",
    "print('Maximum review length: {}'.format(max(review_lens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def remove_zero_length_reviews(reviews_ints, labels):\n",
    "    non_zero_idx = [ii for ii, review in enumerate(reviews_ints) if len(review) != 0]\n",
    "\n",
    "    new_reviews_ints = [reviews_ints[ii] for ii in non_zero_idx]\n",
    "    labels = np.array([labels[ii] for ii in non_zero_idx])\n",
    "    \n",
    "    return new_reviews_ints, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews after removing zero-length review: 49945\n",
      "Number of labels after removing zero-length review: 49945\n"
     ]
    }
   ],
   "source": [
    "reviews_ints, encoded_labels = remove_zero_length_reviews(pre_reviews_ints, all_labels)\n",
    "\n",
    "print('Number of reviews after removing zero-length review: {}'.format(len(reviews_ints)))\n",
    "print('Number of labels after removing zero-length review: {}'.format(len(encoded_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_features(reviews_ints, seq_length=200):\n",
    "    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
    "    for i, row in enumerate(reviews_ints):\n",
    "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
    "        \n",
    "    assert len(features) == len(reviews_ints), \"Features should have as many rows as reviews.\"\n",
    "    assert len(features[0]) == seq_length, \"Each feature row should contain seq_length values.\"\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [  269   488   339  3626   184    17    42   339   110    35  4638  3485]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [   13   100  2169    95   144     1    80    57  9796 10184  2821    40]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0]\n",
      " [  490     1   689   122   334   144     1   112  1400  1202  3411  1906]]\n"
     ]
    }
   ],
   "source": [
    "features = pad_features(reviews_ints)\n",
    "print(features[:25,:12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_valid_test_datasets(features, encoded_labels, batch_size, train_size=39000):\n",
    "    rest = len(features) % batch_size\n",
    "    if rest:\n",
    "        new_features_len = len(features) - rest\n",
    "        features = features[:new_features_len]\n",
    "        encoded_labels = encoded_labels[:new_features_len]\n",
    "    \n",
    "    train_x, remain_x = features[:train_size], features[train_size:]\n",
    "    train_y, remain_y = encoded_labels[:train_size], encoded_labels[train_size:]\n",
    "\n",
    "    test_idx = int(len(remain_x)*0.5)\n",
    "    valid_x, test_x = remain_x[:test_idx], remain_x[test_idx:]\n",
    "    valid_y, test_y = remain_y[:test_idx], remain_y[test_idx:]\n",
    "    \n",
    "    return train_x, train_y, valid_x, valid_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: (39000, 200)\n",
      "Validation dataset: (5450, 200)\n",
      "Test dataset: (5450, 200)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "train_x, train_y, valid_x, valid_y, test_x, test_y = get_train_valid_test_datasets(features, encoded_labels, batch_size)\n",
    "\n",
    "\n",
    "print('Training dataset: {}'.format(train_x.shape))\n",
    "print('Validation dataset: {}'.format(valid_x.shape))\n",
    "print('Test dataset: {}'.format(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data set has 2245 reviews that have the same content.\n",
      "Validation data set has 1302 reviews that have the same content.\n",
      "Test data set has 79 reviews that have the same content.\n"
     ]
    }
   ],
   "source": [
    "unique_train_reviews = set(map(tuple, train_x))\n",
    "print(\"Train data set has {} reviews that have the same content.\".format(len(train_x) - len(unique_train_reviews)))\n",
    "\n",
    "unique_valid_reviews = set(map(tuple, valid_x))\n",
    "print(\"Validation data set has {} reviews that have the same content.\".format(len(valid_x) - len(unique_valid_reviews)))\n",
    "\n",
    "unique_test_reviews = set(map(tuple, test_x))\n",
    "print(\"Test data set has {} reviews that have the same content.\".format(len(test_x) - len(unique_test_reviews)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def get_data_loader(dataset_x, dataset_y, batch_size=batch_size):\n",
    "    tensor_dataset = TensorDataset(torch.from_numpy(dataset_x), torch.from_numpy(dataset_y))\n",
    "    data_loader = DataLoader(tensor_dataset, shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_data_loader(train_x, train_y)\n",
    "valid_loader = get_data_loader(valid_x, valid_y)\n",
    "test_loader = get_data_loader(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample dataset size: torch.Size([50, 200])\n",
      "Sample data: \n",
      "tensor([[   0,    0,    0,  ...,  732,   23, 2157],\n",
      "        [   0,    0,    0,  ...,    2,  719,  825],\n",
      "        [   0,    0,    0,  ...,    5,  940,  373],\n",
      "        ...,\n",
      "        [   0,    0,    0,  ..., 1048,   17,   63],\n",
      "        [   0,    0,    0,  ...,    1,    4,  806],\n",
      "        [   0,    0,    0,  ..., 1193,    1,  689]], dtype=torch.int32)\n",
      "Sample label: \n",
      "tensor([0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
      "        1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "        1, 1], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample dataset size: {}'.format(sample_x.size()))\n",
    "print('Sample data: \\n{}'.format(sample_x))\n",
    "print('Sample label: \\n{}'.format(sample_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Recurrent Neural Network with Long short-term memory layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SentimentRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        \n",
    "        super(SentimentRNN, self).__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.long()\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        sig_out = self.sig(out)\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1]\n",
    "\n",
    "        return sig_out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size, use_cuda):\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if use_cuda:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters and model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (embedding): Embedding(50771, 400)\n",
      "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab_to_int) + 1\n",
    "output_size = 1\n",
    "embedding_dim = 400\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "\n",
    "model = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, valid_loader, epochs, loss_fn, optimizer, use_cuda, save_path, batch_size=batch_size):\n",
    "    counter = 0\n",
    "    print_every = 100\n",
    "    clip = 5\n",
    "    val_loss_min = np.Inf\n",
    "\n",
    "    if use_cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    model.train()\n",
    "    for e in range(epochs):\n",
    "        h = model.init_hidden(batch_size, use_cuda)\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            counter += 1\n",
    "\n",
    "            if use_cuda:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            h = tuple([each.data for each in h])\n",
    "            model.zero_grad()\n",
    "            output, h = model(inputs, h)\n",
    "            loss = loss_fn(output.squeeze(), labels.float())\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "\n",
    "            if counter % print_every == 0:\n",
    "                val_h = model.init_hidden(batch_size, use_cuda)\n",
    "                val_losses = []\n",
    "                model.eval()\n",
    "                \n",
    "                for inputs, labels in valid_loader:\n",
    "\n",
    "                    val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                    if (use_cuda):\n",
    "                        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                    output, val_h = model(inputs, val_h)\n",
    "                    val_loss = loss_fn(output.squeeze(), labels.float())\n",
    "\n",
    "                    val_losses.append(val_loss.item())\n",
    "\n",
    "                model.train()\n",
    "                mean_val_losses = np.mean(val_losses)\n",
    "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                      \"Step: {}...\".format(counter),\n",
    "                      \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                      \"Val Loss: {:.6f}\".format(mean_val_losses))\n",
    "                \n",
    "                if mean_val_losses <= val_loss_min:\n",
    "                    print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(val_loss_min, mean_val_losses))\n",
    "                    torch.save(model.state_dict(), save_path)\n",
    "                    val_loss_min = mean_val_losses\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 4\n",
    "train_model_save_path = './cache/sentiment_analysis/train.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/4... Step: 100... Loss: 0.424100... Val Loss: 0.592706\n",
      "Validation loss decreased (inf --> 0.592706).  Saving model ...\n",
      "Epoch: 1/4... Step: 200... Loss: 0.318558... Val Loss: 0.516958\n",
      "Validation loss decreased (0.592706 --> 0.516958).  Saving model ...\n",
      "Epoch: 1/4... Step: 300... Loss: 0.493396... Val Loss: 0.582965\n",
      "Epoch: 1/4... Step: 400... Loss: 0.385282... Val Loss: 0.518720\n",
      "Epoch: 1/4... Step: 500... Loss: 0.437951... Val Loss: 0.603074\n",
      "Epoch: 1/4... Step: 600... Loss: 0.422860... Val Loss: 0.458582\n",
      "Validation loss decreased (0.516958 --> 0.458582).  Saving model ...\n",
      "Epoch: 1/4... Step: 700... Loss: 0.316570... Val Loss: 0.381392\n",
      "Validation loss decreased (0.458582 --> 0.381392).  Saving model ...\n",
      "Epoch: 2/4... Step: 800... Loss: 0.127956... Val Loss: 0.369119\n",
      "Validation loss decreased (0.381392 --> 0.369119).  Saving model ...\n",
      "Epoch: 2/4... Step: 900... Loss: 0.200017... Val Loss: 0.329930\n",
      "Validation loss decreased (0.369119 --> 0.329930).  Saving model ...\n",
      "Epoch: 2/4... Step: 1000... Loss: 0.288228... Val Loss: 0.186362\n",
      "Validation loss decreased (0.329930 --> 0.186362).  Saving model ...\n",
      "Epoch: 2/4... Step: 1100... Loss: 0.209694... Val Loss: 0.261627\n",
      "Epoch: 2/4... Step: 1200... Loss: 0.327705... Val Loss: 0.284842\n",
      "Epoch: 2/4... Step: 1300... Loss: 0.203754... Val Loss: 0.233799\n",
      "Epoch: 2/4... Step: 1400... Loss: 0.393848... Val Loss: 0.251394\n",
      "Epoch: 2/4... Step: 1500... Loss: 0.273981... Val Loss: 0.173023\n",
      "Validation loss decreased (0.186362 --> 0.173023).  Saving model ...\n",
      "Epoch: 3/4... Step: 1600... Loss: 0.177807... Val Loss: 0.255645\n",
      "Epoch: 3/4... Step: 1700... Loss: 0.111798... Val Loss: 0.219533\n",
      "Epoch: 3/4... Step: 1800... Loss: 0.119133... Val Loss: 0.246551\n",
      "Epoch: 3/4... Step: 1900... Loss: 0.139243... Val Loss: 0.246097\n",
      "Epoch: 3/4... Step: 2000... Loss: 0.227312... Val Loss: 0.125092\n",
      "Validation loss decreased (0.173023 --> 0.125092).  Saving model ...\n",
      "Epoch: 3/4... Step: 2100... Loss: 0.222470... Val Loss: 0.247626\n",
      "Epoch: 3/4... Step: 2200... Loss: 0.269673... Val Loss: 0.174028\n",
      "Epoch: 3/4... Step: 2300... Loss: 0.287069... Val Loss: 0.268322\n",
      "Epoch: 4/4... Step: 2400... Loss: 0.204325... Val Loss: 0.228534\n",
      "Epoch: 4/4... Step: 2500... Loss: 0.235243... Val Loss: 0.206750\n",
      "Epoch: 4/4... Step: 2600... Loss: 0.221967... Val Loss: 0.314287\n",
      "Epoch: 4/4... Step: 2700... Loss: 0.118075... Val Loss: 0.263183\n",
      "Epoch: 4/4... Step: 2800... Loss: 0.191424... Val Loss: 0.302541\n",
      "Epoch: 4/4... Step: 2900... Loss: 0.198850... Val Loss: 0.265579\n",
      "Epoch: 4/4... Step: 3000... Loss: 0.161875... Val Loss: 0.240398\n",
      "Epoch: 4/4... Step: 3100... Loss: 0.372077... Val Loss: 0.244467\n"
     ]
    }
   ],
   "source": [
    "trained_model = train(model, train_loader, valid_loader, epochs, loss_fn, optimizer, use_cuda, train_model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.load_state_dict(torch.load(train_model_save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, loss_fn, use_cuda):\n",
    "    test_losses = []\n",
    "    num_correct = 0\n",
    "    \n",
    "    if use_cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    h = model.init_hidden(batch_size, use_cuda)\n",
    "\n",
    "    model.eval()\n",
    "    for inputs, labels in test_loader:\n",
    "\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        output, h = model(inputs, h)\n",
    "        test_loss = loss_fn(output.squeeze(), labels.float())\n",
    "        test_losses.append(test_loss.item())\n",
    "        pred = torch.round(output.squeeze())\n",
    "        correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "        correct = np.squeeze(correct_tensor.numpy()) if not use_cuda else np.squeeze(correct_tensor.cpu().numpy())\n",
    "        num_correct += np.sum(correct)\n",
    "\n",
    "    print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "    test_acc = num_correct/len(test_loader.dataset)\n",
    "    print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.194\n",
      "Test accuracy: 0.928\n"
     ]
    }
   ],
   "source": [
    "test(trained_model, test_loader, loss_fn, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test custom reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_review(review, vocab_to_int):\n",
    "    words = review_to_words(review)\n",
    "    ints = []\n",
    "    ints.append([vocab_to_int[word] for word in words])\n",
    "\n",
    "    return ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, review, vocab_to_int, use_cuda):\n",
    "    if use_cuda:\n",
    "        model.cuda()\n",
    "        \n",
    "    model.eval()\n",
    "    ints = tokenize_review(review, vocab_to_int)\n",
    "    features = pad_features(ints)\n",
    "    feature_tensor = torch.from_numpy(features)\n",
    "    batch_size = feature_tensor.size(0)\n",
    "    h = model.init_hidden(batch_size, use_cuda)\n",
    "    \n",
    "    if use_cuda:\n",
    "        feature_tensor = feature_tensor.cuda()\n",
    "    \n",
    "    output, h = model(feature_tensor, h)\n",
    "    \n",
    "    pred = torch.round(output.squeeze()) \n",
    "    print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n",
    "    \n",
    "    sentiment_message = '{} review detected.'.format('Positive' if pred.item() == 1 else 'Negative')\n",
    "    print(sentiment_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction value, pre-rounding: 0.859440\n",
      "Positive review detected.\n"
     ]
    }
   ],
   "source": [
    "test_review_pos = \"It's not like that app is good or bad. It sometimes just work but you don't feel it's comfortable. I got this great chance to use an app which is good and comfortable.\"\n",
    "predict(trained_model, test_review_pos, vocab_to_int, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction value, pre-rounding: 0.024830\n",
      "Negative review detected.\n"
     ]
    }
   ],
   "source": [
    "test_review_neg = \"If this application did not have so many errors, I would like it.\"\n",
    "predict(trained_model, test_review_neg, vocab_to_int, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction value, pre-rounding: 0.244205\n",
      "Negative review detected.\n"
     ]
    }
   ],
   "source": [
    "test_review_sentiment = \"To say this application is bad it's like to lie. I don't like to lie that's why I won't say it.\"\n",
    "predict(trained_model, test_review_sentiment, vocab_to_int, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction value, pre-rounding: 0.056693\n",
      "Negative review detected.\n"
     ]
    }
   ],
   "source": [
    "test_review_long_1 = \"First and foremost, it is a great application for someone who is looking for something simple yet sophisticated. It allows for fair number of actions and allows to automate long and tireing processes. With it's admin pannel it is possible to manage and supervise so many aspects of daily tasks, reducing boring tasks to minimum and maximizing cool and initiative challenges! I don't like the layout though. It seems old and not responsive. In 20s I would expect more wow factor. Despite that all the advantages overcome slight shortcomings. The application is superior to anything available on the market right now and I foresee it to stay like that for a long time. I was looking for application like this!\"\n",
    "predict(trained_model, test_review_long_1, vocab_to_int, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction value, pre-rounding: 0.382295\n",
      "Negative review detected.\n"
     ]
    }
   ],
   "source": [
    "test_review_long_2 = \"3D designers did a fine job with landscapes, so user can get impression as if those are from real movie. However, sometimes the interface is sinking with some objects, especially on level two, which spoils the whole effect. Critical error appeared when I wanted to restart game from checkpoint. It needs fixing.\"\n",
    "predict(trained_model, test_review_long_2, vocab_to_int, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction value, pre-rounding: 0.007539\n",
      "Negative review detected.\n"
     ]
    }
   ],
   "source": [
    "test_teview_short = \"App is not working properly. I get error on when I'm tryng to reach any item of the list.\"\n",
    "predict(trained_model, test_teview_short, vocab_to_int, use_cuda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
